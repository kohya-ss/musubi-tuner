# UI Text Dictionary for potential i18n
# I18N Configuration
I18N_DATA = {
    "en": {
        "app_title": "Musubi Tuner GUI",
        "app_header": "# Musubi Tuner GUI",
        "app_desc": "A simple frontend for training LoRA models with Musubi Tuner.",
        "acc_project": "1. Project Settings",
        "desc_project": "All working files will be created under this directory.",
        "lbl_proj_dir": "Project Working Directory",
        "ph_proj_dir": "Absolute path to your project folder",
        "btn_init_project": "Initialize/Load Project",
        "acc_model": "2. Model & Dataset Configuration",
        "desc_model": "Choose the model architecture and specify the ComfyUI models directory.",
        "lbl_model_arch": "Model Architecture",
        "lbl_vram": "VRAM Size (GB)",
        "lbl_comfy_dir": "ComfyUI Models Directory",
        "ph_comfy_dir": "Absolute path to ComfyUI/models",
        "btn_validate_models": "Validate Models Directory",
        "header_dataset": "### 3. Dataset Settings",
        "desc_dataset": "Configure the resolution and batch size for the dataset.",
        "btn_rec_res_batch": "Set Recommended Resolution & Batch Size",
        "lbl_res_w": "Resolution Width",
        "lbl_res_h": "Resolution Height",
        "lbl_batch_size": "Batch Size",
        "btn_gen_config": "Generate Dataset Config",
        "lbl_toml_preview": "TOML Preview",
        "acc_preprocessing": "4. Preprocessing",
        "desc_preprocessing": "Pre-calculate latents and text encoder outputs to speed up training.",
        "btn_set_paths": "Set Default Paths",
        "lbl_vae_path": "VAE Path",
        "ph_vae_path": "Path to VAE model",
        "lbl_te1_path": "Text Encoder 1 Path",
        "ph_te1_path": "Path to Text Encoder 1",
        "lbl_te2_path": "Text Encoder 2 Path",
        "ph_te2_path": "Path to Text Encoder 2 (Optional)",
        "btn_cache_latents": "Cache Latents",
        "btn_cache_text": "Cache Text Encoder Outputs",
        "lbl_cache_log": "Caching Log Output",
        "acc_training": "5. Training",
        "desc_training_basic": "Configure the training parameters.",
        "desc_training_zimage": "Recommended: Use **bf16** for mixed precision. Z-Image requires specific attention to Flow Shift.",
        "btn_rec_params": "Set Recommended Parameters",
        "lbl_dit_path": "Base Model / DiT Path",
        "ph_dit_path": "Path to DiT model",
        "lbl_output_name": "Output LoRA Name",
        "header_basic_params": "### Basic Parameters",
        "lbl_lr": "Learning Rate",
        "lbl_epochs": "Epochs",
        "lbl_save_every": "Save Every N Epochs",
        "accordion_advanced": "Advanced Parameters",
        "desc_training_detailed": """
### detailed explanation
- **Learning Rate**: Controls how much the model weights are updated during training. Lower values are safer but slower.
- **Epochs**: One complete pass through the entire training dataset.
- **Save Every N Epochs**: How often to save the model and generate sample images.
- **Discrete Flow Shift**: A parameter specific to flow matching models. 2.0 is recommended for Z-Image.
- **Block Swap**: Offloads model blocks to CPU to save VRAM. Higher values save more VRAM but slow down training.
- **Mixed Precision**: bf16 is recommended for modern GPUs (RTX 30xx+). fp16 uses less memory but is less stable.
- **Gradient Checkpointing**: Saves VRAM by recomputing activations during backward pass.
- **FP8**: further reduces memory usage by using 8-bit floating point arithmetic.
""",
        "lbl_flow_shift": "Discrete Flow Shift",
        "lbl_block_swap": "Block Swap (0-28)",
        "lbl_mixed_precision": "Mixed Precision",
        "lbl_grad_cp": "Gradient Checkpointing",
        "lbl_fp8_scaled": "FP8 Scaled (DiT) - Enables --fp8_base and --fp8_scaled",
        "lbl_fp8_llm": "FP8 LLM (Text Encoder)",
        "accordion_additional": "Additional Options",
        "desc_additional_args": "Enter any additional command line arguments here. They will be appended to the training command.",
        "lbl_additional_args": "Additional Optional Arguments",
        "ph_additional_args": "--arg value --flag",
        "btn_start_training": "Start Training (New Window)",
        "acc_post_processing": "6. Post-Processing",
        "desc_post_proc": "Convert Z-Image LoRA to ComfyUI format.",
        "lbl_input_lora": "Input LoRA Path",
        "ph_input_lora": "Path to trained .safetensors file",
        "lbl_output_comfy": "Output ComfyUI LoRA Path",
        "ph_output_comfy": "Path to save converted model",
        "btn_convert": "Convert to ComfyUI Format",
        "lbl_conversion_log": "Conversion Log",
        "desc_qwen_notes": "Qwen-Image specific notes here.",
    },
    "ja": {
        "app_title": "Musubi Tuner GUI",
        "app_header": "# Musubi Tuner GUI",
        "app_desc": "Musubi TunerでLoRAモデルを学習するためのシンプルなフロントエンドです。",
        "acc_project": "1. プロジェクト設定",
        "desc_project": "すべての作業ファイルはこのディレクトリ下に作成されます。",
        "lbl_proj_dir": "プロジェクト作業ディレクトリ",
        "ph_proj_dir": "プロジェクトフォルダへの絶対パス",
        "btn_init_project": "プロジェクトを初期化/読み込み",
        "acc_model": "2. モデル＆データセット設定",
        "desc_model": "モデルアーキテクチャを選択し、ComfyUIのモデルディレクトリを指定してください。",
        "lbl_model_arch": "モデルアーキテクチャ",
        "lbl_vram": "VRAMサイズ (GB)",
        "lbl_comfy_dir": "ComfyUI モデルディレクトリ",
        "ph_comfy_dir": "ComfyUI/models への絶対パス",
        "btn_validate_models": "モデルディレクトリを検証",
        "header_dataset": "### 3. データセット設定",
        "desc_dataset": "データセットの解像度とバッチサイズを設定してください。",
        "btn_rec_res_batch": "推奨解像度とバッチサイズを設定",
        "lbl_res_w": "解像度 幅",
        "lbl_res_h": "解像度 高さ",
        "lbl_batch_size": "バッチサイズ",
        "btn_gen_config": "データセット設定(TOML)を生成",
        "lbl_toml_preview": "TOML プレビュー",
        "acc_preprocessing": "4. 前処理 (Preprocessing)",
        "desc_preprocessing": "学習を高速化するためにLatentsとテキストエンコーダーの出力を事前計算します。",
        "btn_set_paths": "デフォルトパスを設定",
        "lbl_vae_path": "VAE パス",
        "ph_vae_path": "VAEモデルへのパス",
        "lbl_te1_path": "テキストエンコーダー1 パス",
        "ph_te1_path": "テキストエンコーダー1へのパス",
        "lbl_te2_path": "テキストエンコーダー2 パス",
        "ph_te2_path": "テキストエンコーダー2へのパス (オプション)",
        "btn_cache_latents": "Latentsをキャッシュ",
        "btn_cache_text": "テキストエンコーダー出力をキャッシュ",
        "lbl_cache_log": "キャッシュログ出力",
        "acc_training": "5. 学習 (Training)",
        "desc_training_basic": "学習パラメータを設定してください。",
        "desc_training_zimage": "推奨: 混合精度には **bf16** を使用してください。Z-ImageはFlow Shiftに注意が必要です。",
        "btn_rec_params": "推奨パラメータを設定",
        "lbl_dit_path": "ベースモデル / DiT パス",
        "ph_dit_path": "DiTモデルへのパス",
        "lbl_output_name": "出力 LoRA 名",
        "header_basic_params": "### 基本パラメータ",
        "lbl_lr": "学習率 (Learning Rate)",
        "lbl_epochs": "エポック数 (Epochs)",
        "lbl_save_every": "Nエポックごとに保存",
        "accordion_advanced": "詳細パラメータ",
        "desc_training_detailed": """
### 詳細説明
- **学習率 (Learning Rate)**: 学習中にモデルの重みをどれくらい更新するかを制御します。低い値の方が安全ですが、学習が遅くなります。
- **エポック数 (Epochs)**: 学習データセット全体を通す回数です。
- **保存頻度 (Save Every N Epochs)**: モデルの保存とサンプル生成を行う頻度です。
- **Discrete Flow Shift**: Flow Matchingモデル特有のパラメータです。Z-Imageでは2.0が推奨されます。
- **Block Swap**: VRAMを節約するためにモデルブロックをCPUにオフロードします。値を大きくするとVRAMを節約できますが、学習が遅くなります。
- **混合精度 (Mixed Precision)**: 最新のGPU(RTX 30xx以降)ではbf16が推奨されます。fp16はメモリ使用量が少ないですが、安定性が低いです。
- **Gradient Checkpointing**: Backwardパス中にアクティベーションを再計算することでVRAMを節約します。
- **FP8**: 8ビット浮動小数点演算を使用することでメモリ使用量をさらに削減します。
""",
        "lbl_flow_shift": "Discrete Flow Shift",
        "lbl_block_swap": "Block Swap (0-28)",
        "lbl_mixed_precision": "混合精度 (Mixed Precision)",
        "lbl_grad_cp": "Gradient Checkpointing",
        "lbl_fp8_scaled": "FP8 Scaled (DiT) - --fp8_base と --fp8_scaled を有効化",
        "lbl_fp8_llm": "FP8 LLM (テキストエンコーダー)",
        "accordion_additional": "追加オプション",
        "desc_additional_args": "追加のコマンドライン引数を入力してください。これらは学習コマンドに追加されます。",
        "lbl_additional_args": "追加のオプション引数",
        "ph_additional_args": "--arg value --flag",
        "btn_start_training": "学習を開始 (新しいウィンドウ)",
        "acc_post_processing": "6. 後処理 (Post-Processing)",
        "desc_post_proc": "Z-Image LoRAをComfyUI形式に変換します。",
        "lbl_input_lora": "入力 LoRA パス",
        "ph_input_lora": "学習済み .safetensors ファイルへのパス",
        "lbl_output_comfy": "出力 ComfyUI LoRA パス",
        "ph_output_comfy": "変換後のモデルの保存先パス",
        "btn_convert": "ComfyUI形式に変換",
        "lbl_conversion_log": "変換ログ",
        "desc_qwen_notes": "Qwen-Image 特有の注意点。",
    },
}
